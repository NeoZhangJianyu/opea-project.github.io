<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Kubernetes installation demo using kubeadm &mdash; OPEA™ 0.8 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../_static/opea-custom.css?v=a771719c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css?v=a5c4661c" />

  
    <link rel="shortcut icon" href="../../../_static/OPEA-favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=a0e24af7"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/opea-custom.js?v=22d49862"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            OPEA™
              <img src="../../../_static/opea-horizontal-white-w200.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> OPEA Project</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Document Versions</dt>
        
          <dd><a href="/latest/">latest</a></dd>
        
      </dl>
      <dl>
        <dt>OPEA Project links</dt>
          <dd>
            <a href="https://opea.dev">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/opea-project/docs/wiki">Wiki</a>
          </dd>
      </dl>
    </div>
  </div>
  
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Documentation Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../develop.html">Developer Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../develop.html#design-guides">Design Guides</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../develop.html#contribute-guides">Contribute Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../developer-guides/docbuild.html">OPEA Documentation Generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#documentation-overview">Documentation Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#set-up-the-documentation-working-folders">Set Up the Documentation Working Folders</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#install-the-documentation-tools">Install the Documentation Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#documentation-presentation-theme">Documentation Presentation Theme</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#run-the-documentation-processors">Run the Documentation Processors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#publish-content">Publish Content</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#document-versioning">Document Versioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../developer-guides/docbuild.html#filter-expected-warnings">Filter Expected Warnings</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../release_notes/index.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../release_notes/v0.8.html">OPEA Release Notes v0.8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.8.html#whats-new-in-opea-v0-8">What’s New in OPEA v0.8</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.8.html#details">Details</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.8.html#thanks-to-these-contributors">Thanks to these contributors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../release_notes/v0.7.html">OPEA Release Notes v0.7</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.7.html#opea-highlights">OPEA Highlights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.7.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.7.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.7.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.7.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../release_notes/v0.6.html">OPEA Release Notes v0.6</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.6.html#opea-highlight">OPEA Highlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.6.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.6.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.6.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../release_notes/v0.6.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
</ul>
</li>
</ul>


        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">OPEA™</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <!-- Latest -->
  
  

  <li><a href="../../../index.html">Latest</a> &raquo;</li>
  
  <li>Kubernetes installation demo using kubeadm</li>

      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/guide/installation/k8s_install/k8s_install_kubeadm.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
  
    <!-- div class="admonition important">
        <p class="admonition-title">Important</p>
        <p>This is the latest documentation for the development branch of
        the OPEA Project (main).<br/>Use the drop-down menu on the left to select
        documentation for a stable release.</p>
    </div -->
  
  
           <div itemprop="articleBody">
             
  <section id="kubernetes-installation-demo-using-kubeadm">
<h1>Kubernetes installation demo using kubeadm<a class="headerlink" href="#kubernetes-installation-demo-using-kubeadm" title="Link to this heading">¶</a></h1>
<p>In this demo, we’ll install Kubernetes v1.29 using official <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/">kubeadm</a> on a 2 node cluster.</p>
<section id="node-configuration">
<h2>Node configuration<a class="headerlink" href="#node-configuration" title="Link to this heading">¶</a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>hostname</p></th>
<th class="head"><p>ip address</p></th>
<th class="head"><p>Operating System</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>k8s-master</p></td>
<td><p>192.168.121.35/24</p></td>
<td><p>Ubuntu 22.04</p></td>
</tr>
<tr class="row-odd"><td><p>k8s-worker</p></td>
<td><p>192.168.121.133/24</p></td>
<td><p>Ubuntu 22.04</p></td>
</tr>
</tbody>
</table>
<p>These 2 nodes needs the following proxy to access the internet:</p>
<ul class="simple">
<li><p>http_proxy=”http://proxy.fake-proxy.com:911”</p></li>
<li><p>https_proxy=”http://proxy.fake-proxy.com:912”</p></li>
</ul>
<p>We assume these 2 nodes have been set correctly with the corresponding proxy so we can access the internet both in bash terminal and in apt repository.</p>
</section>
<section id="step-0-clean-up-the-environment">
<h2>Step 0. Clean up the environment<a class="headerlink" href="#step-0-clean-up-the-environment" title="Link to this heading">¶</a></h2>
<p>If on any of the above 2 nodes, you have previously installed either Kubernetes, or any other container runtime(i.e. docker, containerd, etc.), please make sure you have clean-up those first.</p>
<p>If there is any previous Kubernetes installed on any of these nodes by <code class="docutils literal notranslate"><span class="pre">kubeadm</span></code>, please refer to the listed steps to <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#tear-down">tear down the Kubernetes</a> first.</p>
<p>If there is any previous Kubernetes installed on any of these nodes by <code class="docutils literal notranslate"><span class="pre">kubespray</span></code>, please refer to kubespray doc to <a class="reference external" href="https://kubespray.io/#/?id=quick-start">clean up the Kubernetes</a> first.</p>
<p>Once the Kubernetes is teared down or cleaned up, please run the following command on all the nodes to remove relevant packages:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>apt-get<span class="w"> </span>purge<span class="w"> </span>docker<span class="w"> </span>docker-engine<span class="w"> </span>docker.io<span class="w"> </span>containerd<span class="w"> </span>runc<span class="w"> </span>containerd.io<span class="w"> </span>kubeadm<span class="w"> </span>kubectl<span class="w"> </span>kubelet
sudo<span class="w"> </span>rm<span class="w"> </span>-r<span class="w"> </span>/etc/cni<span class="w"> </span>/etc/kubernetes<span class="w"> </span>/var/lib/kubelet<span class="w"> </span>/var/run/kubernetes<span class="w"> </span>/etc/containerd<span class="w"> </span>/etc/systemd/system/containerd.service.d<span class="w"> </span>/etc/default/kubelet
</pre></div>
</div>
</section>
<section id="step-1-install-relevant-components">
<h2>Step 1. Install relevant components<a class="headerlink" href="#step-1-install-relevant-components" title="Link to this heading">¶</a></h2>
<p>Run the following on all the nodes:</p>
<ol class="arabic simple">
<li><p>Export proxy settings in bash</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span><span class="s2">&quot;http://proxy.fake-proxy.com:911&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span><span class="s2">&quot;http://proxy.fake-proxy.com:912&quot;</span>
<span class="c1"># Please make sure you&#39;ve added all the node&#39;s ip addresses into the no_proxy environment variable</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">no_proxy</span><span class="o">=</span><span class="s2">&quot;localhost,127.0.0.1,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,192.168.121.35,192.168.121.133&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Config system settings</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Disable swap</span>
sudo<span class="w"> </span>swapoff<span class="w"> </span>-a
sudo<span class="w"> </span>sed<span class="w"> </span>-i<span class="w"> </span><span class="s2">&quot;s/^\(.* swap \)/#\1/g&quot;</span><span class="w"> </span>/etc/fstab
<span class="c1"># load kernel module for containerd</span>
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span>
<span class="s">overlay</span>
<span class="s">br_netfilter</span>
<span class="s">EOF</span>
sudo<span class="w"> </span>modprobe<span class="w"> </span>overlay
sudo<span class="w"> </span>modprobe<span class="w"> </span>br_netfilter
<span class="c1"># Enable IPv4 packet forwarding</span>
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span>
<span class="s">net.ipv4.ip_forward = 1</span>
<span class="s">net.bridge.bridge-nf-call-iptables = 1</span>
<span class="s">net.bridge.bridge-nf-call-ip6tables = 1</span>
<span class="s">EOF</span>
sudo<span class="w"> </span>sysctl<span class="w"> </span>--system
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Install containerd CRI and relevant components</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># You may change the component version if necessary</span>
<span class="nv">CONTAINERD_VER</span><span class="o">=</span><span class="s2">&quot;1.7.18&quot;</span>
<span class="nv">RUNC_VER</span><span class="o">=</span><span class="s2">&quot;1.1.12&quot;</span>
<span class="nv">CNI_VER</span><span class="o">=</span><span class="s2">&quot;1.5.0&quot;</span>
<span class="nv">NERDCTL_VER</span><span class="o">=</span><span class="s2">&quot;1.7.6&quot;</span>
<span class="nv">BUILDKIT_VER</span><span class="o">=</span><span class="s2">&quot;0.13.2&quot;</span>

<span class="c1">#Install Runc</span>
wget<span class="w"> </span>https://github.com/opencontainers/runc/releases/download/v<span class="si">${</span><span class="nv">RUNC_VER</span><span class="si">}</span>/runc.amd64
sudo<span class="w"> </span>install<span class="w"> </span>-m<span class="w"> </span><span class="m">755</span><span class="w"> </span>runc.amd64<span class="w"> </span>/usr/local/sbin/runc
rm<span class="w"> </span>-f<span class="w"> </span>runc.amd64

<span class="c1">#Install CNI</span>
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/opt/cni/bin
wget<span class="w"> </span>-c<span class="w"> </span>https://github.com/containernetworking/plugins/releases/download/v<span class="si">${</span><span class="nv">CNI_VER</span><span class="si">}</span>/cni-plugins-linux-amd64-v<span class="si">${</span><span class="nv">CNI_VER</span><span class="si">}</span>.tgz<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tar<span class="w"> </span>xvz<span class="w"> </span>-C<span class="w"> </span>/opt/cni/bin

<span class="c1">#Install Containerd</span>
wget<span class="w"> </span>-c<span class="w"> </span>https://github.com/containerd/containerd/releases/download/v<span class="si">${</span><span class="nv">CONTAINERD_VER</span><span class="si">}</span>/containerd-<span class="si">${</span><span class="nv">CONTAINERD_VER</span><span class="si">}</span>-linux-amd64.tar.gz<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tar<span class="w"> </span>xvz<span class="w"> </span>-C<span class="w"> </span>/usr/local
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/usr/local/lib/systemd/system/containerd.service.d
sudo<span class="w"> </span>-E<span class="w"> </span>wget<span class="w"> </span>https://raw.githubusercontent.com/containerd/containerd/main/containerd.service<span class="w"> </span>-qO<span class="w"> </span>/usr/local/lib/systemd/system/containerd.service
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | sudo tee /usr/local/lib/systemd/system/containerd.service.d/http-proxy.conf</span>
<span class="s">[Service]</span>
<span class="s">Environment=&quot;HTTP_PROXY=${http_proxy}&quot;</span>
<span class="s">Environment=&quot;HTTPS_PROXY=${https_proxy}&quot;</span>
<span class="s">Environment=&quot;NO_PROXY=${no_proxy}&quot;</span>
<span class="s">EOF</span>
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/etc/containerd
sudo<span class="w"> </span>rm<span class="w"> </span>-f<span class="w"> </span>/etc/containerd/config.toml
containerd<span class="w"> </span>config<span class="w"> </span>default<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/containerd/config.toml
sudo<span class="w"> </span>sed<span class="w"> </span>-i<span class="w"> </span><span class="s2">&quot;s/SystemdCgroup = false/SystemdCgroup = true/g&quot;</span><span class="w"> </span>/etc/containerd/config.toml
sudo<span class="w"> </span>systemctl<span class="w"> </span>daemon-reload
sudo<span class="w"> </span>systemctl<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>--now<span class="w"> </span>containerd
sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>containerd

<span class="c1">#Install nerdctl</span>
wget<span class="w"> </span>-c<span class="w"> </span>https://github.com/containerd/nerdctl/releases/download/v<span class="si">${</span><span class="nv">NERDCTL_VER</span><span class="si">}</span>/nerdctl-<span class="si">${</span><span class="nv">NERDCTL_VER</span><span class="si">}</span>-linux-amd64.tar.gz<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tar<span class="w"> </span>xvz<span class="w"> </span>-C<span class="w"> </span>/usr/local/bin

<span class="c1">#You may skip buildkit installation if you don&#39;t need to build container images.</span>
<span class="c1">#Install buildkit</span>
wget<span class="w"> </span>-c<span class="w"> </span>https://github.com/moby/buildkit/releases/download/v<span class="si">${</span><span class="nv">BUILDKIT_VER</span><span class="si">}</span>/buildkit-v<span class="si">${</span><span class="nv">BUILDKIT_VER</span><span class="si">}</span>.linux-amd64.tar.gz<span class="w"> </span>-qO<span class="w"> </span>-<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tar<span class="w"> </span>xvz<span class="w"> </span>-C<span class="w"> </span>/usr/local
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/etc/buildkit
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | sudo tee /etc/buildkit/buildkitd.toml</span>
<span class="s">[worker.oci]</span>
<span class="s">  enabled = false</span>
<span class="s">[worker.containerd]</span>
<span class="s">  enabled = true</span>
<span class="s">  # namespace should be &quot;k8s.io&quot; for Kubernetes (including Rancher Desktop)</span>
<span class="s">  namespace = &quot;default&quot;</span>
<span class="s">EOF</span>
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>/usr/local/lib/systemd/system/buildkit.service.d
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | sudo tee /usr/local/lib/systemd/system/buildkit.service.d/http-proxy.conf</span>
<span class="s">[Service]</span>
<span class="s">Environment=&quot;HTTP_PROXY=${http_proxy}&quot;</span>
<span class="s">Environment=&quot;HTTPS_PROXY=${https_proxy}&quot;</span>
<span class="s">Environment=&quot;NO_PROXY=${no_proxy}&quot;</span>
<span class="s">EOF</span>
sudo<span class="w"> </span>-E<span class="w"> </span>wget<span class="w"> </span>https://raw.githubusercontent.com/moby/buildkit/v<span class="si">${</span><span class="nv">BUILDKIT_VER</span><span class="si">}</span>/examples/systemd/system/buildkit.service<span class="w"> </span>-qO<span class="w"> </span>/usr/local/lib/systemd/system/buildkit.service
sudo<span class="w"> </span>-E<span class="w"> </span>wget<span class="w"> </span>https://raw.githubusercontent.com/moby/buildkit/v<span class="si">${</span><span class="nv">BUILDKIT_VER</span><span class="si">}</span>/examples/systemd/system/buildkit.socket<span class="w"> </span>-qO<span class="w"> </span>/usr/local/lib/systemd/system/buildkit.socket
sudo<span class="w"> </span>systemctl<span class="w"> </span>daemon-reload
sudo<span class="w"> </span>systemctl<span class="w"> </span><span class="nb">enable</span><span class="w"> </span>--now<span class="w"> </span>buildkit
sudo<span class="w"> </span>systemctl<span class="w"> </span>restart<span class="w"> </span>buildkit
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Install kubeadm and related components</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># You may change the component version if necessary</span>
<span class="nv">K8S_VER</span><span class="o">=</span><span class="s2">&quot;1.29&quot;</span>

<span class="c1">#Install kubeadm/kubectl/kubelet</span>
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>apt-transport-https<span class="w"> </span>ca-certificates<span class="w"> </span>curl<span class="w"> </span>gpg
sudo<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>-m<span class="w"> </span><span class="m">755</span><span class="w"> </span>/etc/apt/keyrings
curl<span class="w"> </span>-fsSL<span class="w"> </span>https://pkgs.k8s.io/core:/stable:/v<span class="si">${</span><span class="nv">K8S_VER</span><span class="si">}</span>/deb/Release.key<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>gpg<span class="w"> </span>--dearmor<span class="w"> </span>-o<span class="w"> </span>/etc/apt/keyrings/kubernetes-apt-keyring.gpg<span class="w"> </span>--yes
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="si">${</span><span class="nv">K8S_VER</span><span class="si">}</span><span class="s2">/deb/ /&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/kubernetes.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>kubelet<span class="w"> </span>kubeadm<span class="w"> </span>kubectl
</pre></div>
</div>
</section>
<section id="step-2-create-the-k8s-cluster">
<h2>Step 2. Create the k8s cluster<a class="headerlink" href="#step-2-create-the-k8s-cluster" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>(optional) Install helm v3: on node k8s-master, run the following commands:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#You may skip helm v3 installation if you don&#39;t plan to use helm</span>
curl<span class="w"> </span>https://baltocdn.com/helm/signing.asc<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>apt-key<span class="w"> </span>add<span class="w"> </span>-
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;deb https://baltocdn.com/helm/stable/debian/ all main&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/apt/sources.list.d/helm-stable-debian.list
sudo<span class="w"> </span>apt-get<span class="w"> </span>update
sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>helm
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Initialize the Kubernetes control-plane node: on node k8s-master, run the following commands:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">POD_CIDR</span><span class="o">=</span><span class="s2">&quot;10.244.0.0/16&quot;</span>
sudo<span class="w"> </span>-E<span class="w"> </span>kubeadm<span class="w"> </span>init<span class="w"> </span>--pod-network-cidr<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">POD_CIDR</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
<p>Once succeed, you’ll find the kubeadm’s output such as the following. Please record the <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">join</span></code> command line for later use.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

 mkdir -p $HOME/.kube
 sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

 export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:
 https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 192.168.121.35:6443 --token 26tg15.km2ru94h9ht9h6ou \
       --discovery-token-ca-cert-hash sha256:123f3f8ebaf62f8dfc4542360e5103842408a6cdf630af159e2abc260201ba99
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Create kubectl configuration for a regular user: on node k8s-master, run the following commands:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>-p<span class="w"> </span><span class="nv">$HOME</span>/.kube
sudo<span class="w"> </span>cp<span class="w"> </span>-i<span class="w"> </span>/etc/kubernetes/admin.conf<span class="w"> </span><span class="nv">$HOME</span>/.kube/config
sudo<span class="w"> </span>chown<span class="w"> </span><span class="k">$(</span>id<span class="w"> </span>-u<span class="k">)</span>:<span class="k">$(</span>id<span class="w"> </span>-g<span class="k">)</span><span class="w"> </span><span class="nv">$HOME</span>/.kube/config
<span class="c1"># install bash-completion for kubectl</span>
sudo<span class="w"> </span>apt-get<span class="w"> </span>install<span class="w"> </span>-y<span class="w"> </span>bash-completion
kubectl<span class="w"> </span>completion<span class="w"> </span>bash<span class="w"> </span><span class="p">|</span><span class="w"> </span>sudo<span class="w"> </span>tee<span class="w"> </span>/etc/bash_completion.d/kubectl
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Install Kubernetes CNI Calico: on node k8s-master, run the following commands:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Please set correct NODE_CIDR based on your node ip address.</span>
<span class="c1"># In this example, because both nodes are in 192.168.121.0/24 subnet,</span>
<span class="c1"># we set NODE_CIDR accordingly.</span>
<span class="nv">NODE_CIDR</span><span class="o">=</span><span class="s2">&quot;192.168.121.0/24&quot;</span>
<span class="c1"># You may change the component version if necessary</span>
<span class="nv">CALICO_VER</span><span class="o">=</span><span class="s2">&quot;3.28.0&quot;</span>
kubectl<span class="w"> </span>create<span class="w"> </span>-f<span class="w"> </span><span class="s2">&quot;https://raw.githubusercontent.com/projectcalico/calico/v</span><span class="si">${</span><span class="nv">CALICO_VER</span><span class="si">}</span><span class="s2">/manifests/tigera-operator.yaml&quot;</span>
sleep<span class="w"> </span><span class="m">10</span>
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | kubectl create -f -</span>
<span class="s"># This section includes base Calico installation configuration.</span>
<span class="s"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation</span>
<span class="s">apiVersion: operator.tigera.io/v1</span>
<span class="s">kind: Installation</span>
<span class="s">metadata:</span>
<span class="s">  name: default</span>
<span class="s">spec:</span>
<span class="s">  # Configures Calico networking.</span>
<span class="s">  calicoNetwork:</span>
<span class="s">    ipPools:</span>
<span class="s">    - name: default-ipv4-ippool</span>
<span class="s">      blockSize: 26</span>
<span class="s">      cidr: ${POD_CIDR}</span>
<span class="s">      encapsulation: VXLANCrossSubnet</span>
<span class="s">      natOutgoing: Enabled</span>
<span class="s">      nodeSelector: all()</span>
<span class="s">    nodeAddressAutodetectionV4:</span>
<span class="s">      cidrs: [&quot;${NODE_CIDR}&quot;]</span>
<span class="s">---</span>
<span class="s"># This section configures the Calico API server.</span>
<span class="s"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer</span>
<span class="s">apiVersion: operator.tigera.io/v1</span>
<span class="s">kind: APIServer</span>
<span class="s">metadata:</span>
<span class="s">  name: default</span>
<span class="s">spec: {}</span>
<span class="s">EOF</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Join Kubernetes worker nodes: on node k8s-worker, run the following commands:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># run the kubeadm join command which we recorded at the end of the step 2.4</span>
sudo<span class="w"> </span>kubeadm<span class="w"> </span>join<span class="w"> </span><span class="m">192</span>.168.121.35:6443<span class="w"> </span>--token<span class="w"> </span>26tg15.km2ru94h9ht9h6ou<span class="w"> </span>--discovery-token-ca-cert-hash<span class="w"> </span>sha256:123f3f8ebaf62f8dfc4542360e5103842408a6cdf630af159e2abc260201ba99
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p>On Kubernetes master node, verify that all nodes are joined successfully:</p></li>
</ol>
<p>Run command <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">pod</span> <span class="pre">-A</span></code> to make sure all pods are in ‘Running’ status. If any of the pods are not in ‘Running’ status, please retry the above command. It could take up to several minutes for all the pods to be ready.</p>
<p>Possible output of pod status could be something like</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vagrant@k8s-master:~$ kubectl get pod -A
NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-59c8dc5bff-ff9vs          1/1     Running   0          3m15s
calico-apiserver   calico-apiserver-59c8dc5bff-zblxr          1/1     Running   0          3m15s
calico-system      calico-kube-controllers-596b8f9f7d-68nnp   1/1     Running   0          5m19s
calico-system      calico-node-gcng6                          1/1     Running   0          5m20s
calico-system      calico-node-xlwsb                          1/1     Running   0          2m7s
calico-system      calico-typha-65f5745579-l29v8              1/1     Running   0          5m20s
calico-system      csi-node-driver-q5gmm                      2/2     Running   0          2m7s
calico-system      csi-node-driver-xrhw5                      2/2     Running   0          5m19s
kube-system        coredns-76f75df574-5z57n                   1/1     Running   0          25m
kube-system        coredns-76f75df574-88pkk                   1/1     Running   0          25m
kube-system        etcd-k8s-master                            1/1     Running   0          25m
kube-system        kube-apiserver-k8s-master                  1/1     Running   0          25m
kube-system        kube-controller-manager-k8s-master         1/1     Running   0          25m
kube-system        kube-proxy-jbd6r                           1/1     Running   0          2m7s
kube-system        kube-proxy-lrgb6                           1/1     Running   0          25m
kube-system        kube-scheduler-k8s-master                  1/1     Running   0          25m
tigera-operator    tigera-operator-76c4974c85-lx79h           1/1     Running   0          10m
</pre></div>
</div>
<p>Run command <code class="docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span> <span class="pre">node</span></code> to make sure all node are in ‘Ready’ status. Possible output should be something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vagrant@k8s-master:~$ kubectl get node
NAME          STATUS   ROLES           AGE     VERSION
k8s-master    Ready    control-plane   31m     v1.29.6
k8s-worker1   Ready    &lt;none&gt;          7m31s   v1.29.6
</pre></div>
</div>
</section>
<section id="step-3-optional-reset-kubernetes-cluster">
<h2>Step 3 (optional) Reset Kubernetes cluster<a class="headerlink" href="#step-3-optional-reset-kubernetes-cluster" title="Link to this heading">¶</a></h2>
<p>In some cases, you may want to reset the Kubernetes cluster in case some commands after <code class="docutils literal notranslate"><span class="pre">kubeadm</span> <span class="pre">init</span></code> fail and you want to reinstall Kubernetes. Please check <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#tear-down">tear down the Kubernetes</a> for details.</p>
<p>Below is the example of how to reset the Kubernetes cluster we just created:</p>
<p>On node k8s-master, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># drain node k8s-worker1</span>
kubectl<span class="w"> </span>drain<span class="w"> </span>k8s-worker1<span class="w"> </span>--delete-emptydir-data<span class="w"> </span>--force<span class="w"> </span>--ignore-daemonsets
</pre></div>
</div>
<p>On node k8s-worker1, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>kubeadm<span class="w"> </span>reset
<span class="c1"># manually reset iptables/ipvs if necessary</span>
</pre></div>
</div>
<p>On node k8s-master, delete node k8s-worker1:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl<span class="w"> </span>delete<span class="w"> </span>node<span class="w"> </span>k8s-worker1
</pre></div>
</div>
<p>On node k8s-master, clean up the master node:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>sudo<span class="w"> </span>kubeadm<span class="w"> </span>reset
<span class="c1"># manually reset iptables/ipvs if necessary</span>
</pre></div>
</div>
</section>
<section id="notes">
<h2>NOTES<a class="headerlink" href="#notes" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>By default, normal workload won’t be scheduled to nodes in <code class="docutils literal notranslate"><span class="pre">control-plane</span></code> K8S role(i.e. K8S master node). If you want K8S to schedule normal workload to those nodes, please run the following commands on K8S master node:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl<span class="w"> </span>taint<span class="w"> </span>nodes<span class="w"> </span>--all<span class="w"> </span>node-role.kubernetes.io/control-plane-
kubectl<span class="w"> </span>label<span class="w"> </span>nodes<span class="w"> </span>--all<span class="w"> </span>node.kubernetes.io/exclude-from-external-load-balancers-
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Verifying K8S CNI
If you see any issues of the inter-node pod-to-pod communication, please use the following steps to verify that k8s CNI is working correctly:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the K8S manifest file for our debug pods</span>
cat<span class="w"> </span><span class="s">&lt;&lt;EOF | tee debug.yaml</span>
<span class="s">apiVersion: apps/v1</span>
<span class="s">kind: Deployment</span>
<span class="s">metadata:</span>
<span class="s">  labels:</span>
<span class="s">    run: debug</span>
<span class="s">  name: debug</span>
<span class="s">spec:</span>
<span class="s">  replicas: 2</span>
<span class="s">  selector:</span>
<span class="s">    matchLabels:</span>
<span class="s">      run: debug</span>
<span class="s">  template:</span>
<span class="s">    metadata:</span>
<span class="s">      labels:</span>
<span class="s">        run: debug</span>
<span class="s">    spec:</span>
<span class="s">      affinity:</span>
<span class="s">        podAntiAffinity:</span>
<span class="s">          requiredDuringSchedulingIgnoredDuringExecution:</span>
<span class="s">          - labelSelector:</span>
<span class="s">              matchExpressions:</span>
<span class="s">              - key: run</span>
<span class="s">                operator: In</span>
<span class="s">                values:</span>
<span class="s">                - debug</span>
<span class="s">            topologyKey: kubernetes.io/hostname</span>
<span class="s">      containers:</span>
<span class="s">      - image: nicolaka/netshoot:latest</span>
<span class="s">        name: debug</span>
<span class="s">        command: [ &quot;sleep&quot;, &quot;infinity&quot; ]</span>
<span class="s">EOF</span>
<span class="c1"># Create the debug pod</span>
kubectl<span class="w"> </span>apply<span class="w"> </span>-f<span class="w"> </span>debug.yaml
</pre></div>
</div>
<p>Wait until all 2 debug pods are in ‘Running’ status:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vagrant@k8s-master:~$ kubectl get pod -owide
NAME                    READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES
debug-ddfd698ff-7gsdc   1/1     Running   0          91s   10.244.194.66    k8s-worker1   &lt;none&gt;           &lt;none&gt;
debug-ddfd698ff-z5qpv   1/1     Running   0          91s   10.244.235.199   k8s-master    &lt;none&gt;           &lt;none&gt;
</pre></div>
</div>
<p>Make sure pod <code class="docutils literal notranslate"><span class="pre">debug-ddfd698ff-z5qpv</span></code> on node k8s-master can ping to the ip address of another pod <code class="docutils literal notranslate"><span class="pre">debug-ddfd698ff-7gsdc</span></code> on node k8s-worker1 to verify east-west traffic is working in K8S.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vagrant@k8s-master:~$ kubectl exec debug-ddfd698ff-z5qpv -- ping -c 1 10.244.194.66
PING 10.244.194.66 (10.244.194.66) 56(84) bytes of data.
64 bytes from 10.244.194.66: icmp_seq=1 ttl=62 time=1.76 ms

--- 10.244.194.66 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.755/1.755/1.755/0.000 ms
</pre></div>
</div>
<p>Make sure pod <code class="docutils literal notranslate"><span class="pre">debug-ddfd698ff-z5qpv</span></code> on node k8s-master can ping to the ip address of another node <code class="docutils literal notranslate"><span class="pre">k8s-worker1</span></code> to verify north-south traffic is working in K8S.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>vagrant@k8s-master:~$ kubectl exec debug-ddfd698ff-z5qpv -- ping -c 1 192.168.121.133
PING 192.168.121.133 (192.168.121.133) 56(84) bytes of data.
64 bytes from 192.168.121.133: icmp_seq=1 ttl=63 time=1.34 ms

--- 192.168.121.133 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 1.339/1.339/1.339/0.000 ms
</pre></div>
</div>
<p>Delete debug pods after use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl<span class="w"> </span>delete<span class="w"> </span>-f<span class="w"> </span>debug.yaml
</pre></div>
</div>
</section>
</section>


           </div>
          </div>

          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024-2024 OPEA™, a Series of LF Projects, LLC.

<!-- span class="lastupdated">Last updated on Aug 05, 2024. Published on </span -->
<span class="lastupdated">Published on Aug 05, 2024.</span>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>